#!/usr/bin/env python

import os
from pathlib import Path
import sys
import codecs

from nltk.tokenize import TreebankWordTokenizer

tokenizer = TreebankWordTokenizer()

checkpoint_path = Path(os.environ["LMZOO_CHECKPOINT_PATH"])
vocab_path = checkpoint_path / Path(os.environ["LMZOO_VOCABULARY_PATH"])
with vocab_path.open("r", encoding="utf-8") as f:
    vocab = [line.strip() for line in f]

sys.path.append("/opt/tinylstm")
from get_raw import unkify

for line in codecs.open(sys.argv[1], encoding="utf-8"):
    tokens = tokenizer.tokenize(line.strip())
    tokens = unkify(tokens, vocab)
    print(" ".join(tokens))
